{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c202a11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/RandomSampling/RandomSampling.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac035e8",
   "metadata": {},
   "source": [
    "# 随机种子相关"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "## seed\n",
    "将用于生成随机数的种子设置为非确定性随机数。返回用于随机数生成器（Random Number Generator, RNG）种子的64位数字。\n",
    "\n",
    "**定义**：  \n",
    "torch.seed()\n",
    "\n",
    "**参数**:  \n",
    "- device (torch.device, optional) – the desired device for the generator.  generator所需的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f6bc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409617115381600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c2af942",
   "metadata": {},
   "source": [
    "## manual_seed\n",
    "设置生成随机数的种子。返回一个torch.Generator对象。\n",
    "manual_seed()用于设置RNG的种子，以确保生成的随机数序列是可重复的\n",
    "\n",
    "**定义**：  \n",
    "torch.manual_seed(seed)\n",
    "\n",
    "**参数**:  \n",
    "- seed (int) – The desired seed. Value must be within the inclusive range [-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]. Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula 0xffff_ffff_ffff_ffff + seed.  所需的种子。值必须包含在[-0x8000_0000_0000_0000, 0xffff_ffff_ffff]范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12c2f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1188,  0.0635, -1.4555, -0.0126, -0.1548])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "seed = 666\n",
    "torch.manual_seed(seed)\n",
    "torch.randn(5) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a50d5ff4",
   "metadata": {},
   "source": [
    "## initial_seed\n",
    "返回当前RNG种子的初始值。该函数可以用来检查当前的RNG种子是由哪个初始种子生成的。\n",
    "\n",
    "**定义**：  \n",
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df4a5365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1188,  0.0635, -1.4555, -0.0126, -0.1548])\n",
      "666\n",
      "tensor([-0.0927,  2.5916,  0.4542, -0.6890, -0.9962])\n",
      "666\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "seed = 666\n",
    "torch.manual_seed(seed)\n",
    "print(torch.randn(5))\n",
    "print(torch.initial_seed())\n",
    "\n",
    "print(torch.randn(5))\n",
    "print(torch.initial_seed())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85112f75",
   "metadata": {},
   "source": [
    "## get_rng_state\n",
    "返回随机数生成器状态(torch.ByteTensor)\n",
    "\n",
    "**定义**：  \n",
    "torch.get_rng_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1991f6b4",
   "metadata": {},
   "source": [
    "## set_rng_state\n",
    "设置随机数生成器状态\n",
    "\n",
    "**定义**：  \n",
    "torch.set_rng_state(new_state)\n",
    "\n",
    "**参数**：\n",
    "- new_state (torch.ByteTensor) – The desired state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a37dc10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([154,   2,   0,  ...,   0,   0,   0], dtype=torch.uint8)\n",
      "tensor([-0.1043, -0.5187,  0.1231,  0.0755,  0.7091])\n",
      "tensor([-0.1043, -0.5187,  0.1231,  0.0755,  0.7091])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "new_state = torch.get_rng_state()\n",
    "print(new_state)\n",
    "print(torch.randn(5))\n",
    "\n",
    "torch.set_rng_state(new_state)\n",
    "print(torch.randn(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e44a1d50",
   "metadata": {},
   "source": [
    "# 随机抽样"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd2e408a",
   "metadata": {},
   "source": [
    "## bernoulli\n",
    "从伯努利分布中抽取二进制随机数(0或1)。\n",
    "\n",
    "$$\\text{out}_i\\sim\\operatorname{Bernoulli}(p=\\operatorname{input}_i)$$\n",
    "\n",
    "**定义**：  \n",
    "torch.bernoulli(input, *, generator=None, out=None) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the input tensor of probability values for the Bernoulli distribution   伯努利分布的概率值的输入张量\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling  用于采样的伪随机数生成器\n",
    "\n",
    "- out (Tensor, optional) – the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01678a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(5,5)*0.5\n",
    "# torch.manual_seed(666)\n",
    "torch.bernoulli(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "314ada83",
   "metadata": {},
   "source": [
    "## multinomial\n",
    "返回一个张量，其中每行包含从张量输入的相应行中抽样的多项概率分布的num_samples索引。\n",
    "\n",
    "**定义**：  \n",
    "torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) → LongTensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the input tensor containing probabilities  包含概率的输入张量\n",
    "\n",
    "- num_samples (int) – number of samples to draw\n",
    "\n",
    "- replacement (bool, optional) – whether to draw with replacement or not  是否放回\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling\n",
    "\n",
    "- out (Tensor, optional) – the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10109175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 0, 3, 3, 3, 0, 3, 2, 3, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# create a tensor of weights\n",
    "weights = torch.tensor([1, 1, 1, 5], dtype=torch.float)\n",
    "torch.multinomial(input=weights, num_samples=20, replacement=True)\n",
    "# 每个样本都从weights的多项式分布中抽取"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbbe7d6a",
   "metadata": {},
   "source": [
    "## normal\n",
    "返回一个从均值和标准差给定的独立正态分布中抽取的随机数张量。\n",
    "\n",
    "**定义**：  \n",
    "torch.normal(mean, std, *, generator=None, out=None) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- mean (Tensor) – the tensor of per-element means  每个元素均值的张量\n",
    "\n",
    "- std (Tensor) – the tensor of per-element standard deviations  每个元素标准差的张量\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling\n",
    "\n",
    "- out (Tensor, optional) – the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9fb95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1790,  1.9300, -0.3390,  4.6468,  4.8345,  6.6075,  7.2050,  7.3532,\n",
       "         9.1929, 10.1335])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ea61578",
   "metadata": {},
   "source": [
    "## poisson\n",
    "返回一个与输入相同大小的张量，每个元素从泊松分布中采样\n",
    "\n",
    "$$\\text{out}_i\\sim\\operatorname{Poisson}(\\operatorname{input}_i)$$\n",
    "\n",
    "**定义**：  \n",
    "torch.poisson(input, generator=None) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the input tensor containing the rates of the Poisson distribution  包含泊松分布率的输入张量\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "135a0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5595, 1.3507, 0.5589, 0.5060],\n",
      "        [0.9384, 0.0904, 1.6583, 0.4231],\n",
      "        [2.8662, 0.0395, 1.2601, 2.7589],\n",
      "        [4.3923, 2.6407, 2.4804, 4.8957]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [3., 0., 2., 2.],\n",
       "        [4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(666)\n",
    "rates = torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n",
    "print(rates)\n",
    "torch.poisson(rates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c04563cc",
   "metadata": {},
   "source": [
    "## rand\n",
    "返回一个张量，该张量由[0,1)区间上均匀分布的随机数填充\n",
    "\n",
    "**定义**：  \n",
    "torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- size (int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.  形状\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling  随机数生成器\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.  将创建的tensor赋值给out，共享内存\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()).  返回张量的期望数据类型。\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.  返回张量的期望布局\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.  张量的期望设备\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.  是否记录张量的梯度\n",
    "\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False.  如果设置，返回的张量将分配到固定内存中。\n",
    "pin_memory 是 PyTorch 中一种优化技术，它可以在 CPU 和 GPU 之间高速地复制数据，以加速数据的传输。在 PyTorch 中，可以通过在 Dataset 类中设置 pin_memory=True 来启用 pin_memory 技术。需要注意的是，pin_memory 技术需要更多的内存来存储固定内存区域中的数据，因此如果内存有限，可能需要考虑关闭 pin_memory 技术。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25805133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1877, 0.0181, 0.3317],\n",
       "        [0.0846, 0.5732, 0.0079]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(666)\n",
    "torch.rand(4)\n",
    "torch.rand(2, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16521d24",
   "metadata": {},
   "source": [
    "## rand_like\n",
    "返回一个与输入大小相同的张量，该张量由[0,1)区间上均匀分布的随机数填充\n",
    "\n",
    "**定义**：  \n",
    "torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the size of input will determine size of the output tensor.  输入的大小将决定输出张量的大小\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input.  返回张量的期望数据类型\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input.  返回张量的期望布局\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input.  返回张量的期望设备。\n",
    " \n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.  是否记录张量的梯度\n",
    "\n",
    "- memory_format (torch.memory_format, optional) – the desired memory format of returned Tensor. Default: torch.preserve_format.  返回的张量的期望内存格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e20a2c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3119, 0.2701, 0.1118],\n",
       "        [0.1012, 0.1877, 0.0181]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(666)\n",
    "a = torch.ones(2, 3)\n",
    "torch.rand_like(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8996e5eb",
   "metadata": {},
   "source": [
    "## randint\n",
    "\n",
    "**定义**：  \n",
    "torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- low (int, optional) – Lowest integer to be drawn from the distribution. Default: 0.  从分布中抽取的最小整数。默认值:0。\n",
    "\n",
    "- high (int) – One above the highest integer to be drawn from the distribution.  从分布中抽取的最大整数，不包括。\n",
    "\n",
    "- size (tuple) – a tuple defining the shape of the output tensor.  定义输出张量形状的元组。\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.\n",
    "\n",
    "- dtype (torch.dtype, optional) – if None, this function returns a tensor with dtype torch.int64.\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86f879da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 2, 1, 2],\n",
       "        [2, 1, 1, 1, 2],\n",
       "        [1, 2, 1, 1, 1],\n",
       "        [2, 1, 2, 1, 1],\n",
       "        [2, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randint(low=1, high=3, size=(5, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0cd32d2",
   "metadata": {},
   "source": [
    "## randint_like\n",
    "返回一个与张量输入形状相同的张量，填充在low(包含)和high(不包含)之间均匀生成的随机整数。\n",
    "\n",
    "**定义**：  \n",
    "torch.randint_like(input, low=0, high, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the size of input will determine size of the output tensor.  输入的大小将决定输出张量的大小。\n",
    "\n",
    "- low (int, optional) – Lowest integer to be drawn from the distribution. Default: 0.\n",
    "\n",
    "- high (int) – One above the highest integer to be drawn from the distribution.\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input.\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input.\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input.\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "\n",
    "- memory_format (torch.memory_format, optional) – the desired memory format of returned Tensor. Default: torch.preserve_format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "51fe7889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 1.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3,3)\n",
    "torch.randint_like(input=a,low=0,high=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3a1aef3",
   "metadata": {},
   "source": [
    "## randn\n",
    "返回一个由均值为0，方差为1的正态分布(也称为标准正态分布)中的随机数填充的张量。\n",
    "$$\\text{out}_i\\sim\\mathcal{N}(0,1)$$\n",
    "\n",
    "**定义**：  \n",
    "torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- size (int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()).\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8cfaf288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3615,  0.4625, -0.6849],\n",
       "        [-1.7486, -1.5345, -0.9446]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randn(2, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3716523",
   "metadata": {},
   "source": [
    "## randn_like\n",
    "\n",
    "**定义**：  \n",
    "torch.randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- input (Tensor) – the size of input will determine size of the output tensor.  输入的大小将决定输出张量的大小。\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input.\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input.\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input.\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "\n",
    "- memory_format (torch.memory_format, optional) – the desired memory format of returned Tensor. Default: torch.preserve_format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4d8bafb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8604,  0.3904,  3.3089],\n",
       "        [ 0.5811,  1.6342, -1.5522],\n",
       "        [ 1.0125,  1.3283, -0.6265]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3,3)\n",
    "torch.randn_like(input=a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "949a3377",
   "metadata": {},
   "source": [
    "## randperm\n",
    "返回从0到n - 1的整数的随机排列。\n",
    "\n",
    "**定义**：  \n",
    "torch.randperm(n, *, generator=None, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor\n",
    "\n",
    "**参数**：\n",
    "- n (int) – the upper bound (exclusive)  上限(不包含)\n",
    "\n",
    "- generator (torch.Generator, optional) – a pseudorandom number generator for sampling\n",
    "\n",
    "- out (Tensor, optional) – the output tensor.\n",
    "\n",
    "- dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: torch.int64.\n",
    "\n",
    "- layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "- requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "\n",
    "- pin_memory (bool, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fbaeb553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4099f17",
   "metadata": {},
   "source": [
    "## xxx\n",
    "\n",
    "**定义**：  \n",
    "\n",
    "\n",
    "**参数**：\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb380208",
   "metadata": {},
   "source": [
    "## xxx\n",
    "\n",
    "**定义**：  \n",
    "\n",
    "\n",
    "**参数**：\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a9064",
   "metadata": {},
   "source": [
    "## xxx\n",
    "\n",
    "**定义**：  \n",
    "\n",
    "\n",
    "**参数**：\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
