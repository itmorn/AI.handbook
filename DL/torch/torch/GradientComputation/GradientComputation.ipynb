{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c202a11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/GradientComputation/GradientComputation.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# no_grad\n",
    "禁用梯度计算的上下文管理器。\n",
    "\n",
    "**定义**：  \n",
    "torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae0139b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "  y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af856e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ec8858c",
   "metadata": {},
   "source": [
    "# enable_grad\n",
    "起用梯度计算的上下文管理器。\n",
    "\n",
    "**定义**：  \n",
    "torch.enable_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19109c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "  with torch.enable_grad():\n",
    "    y = x * 2\n",
    "print(y.requires_grad)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c688507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "@torch.enable_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adf47c66",
   "metadata": {},
   "source": [
    "# set_grad_enabled\n",
    "\n",
    "**定义**：  \n",
    "torch.set_grad_enabled(mode)\n",
    "\n",
    "**参数**:  \n",
    "- mode (bool) – Flag whether to enable grad (True), or disable (False). This can be used to conditionally enable gradients.  标记是否启用grad (True)或禁用grad (False)。这可以用来有条件地启用梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05361c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "is_train = False\n",
    "with torch.set_grad_enabled(is_train):\n",
    "  y = x * 2\n",
    "print(y.requires_grad)\n",
    "_ = torch.set_grad_enabled(True)\n",
    "y = x * 2\n",
    "print(y.requires_grad)\n",
    "_ = torch.set_grad_enabled(False)\n",
    "y = x * 2\n",
    "print(y.requires_grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e3d009b",
   "metadata": {},
   "source": [
    "# is_grad_enabled\n",
    "如果当前启用梯度模式，则返回True。\n",
    "\n",
    "**定义**：  \n",
    "torch.is_grad_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880384f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "is_train = False\n",
    "with torch.set_grad_enabled(is_train):\n",
    "  y = x * 2\n",
    "print(torch.is_grad_enabled())\n",
    "_ = torch.set_grad_enabled(True)\n",
    "print(torch.is_grad_enabled())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "434aea1f",
   "metadata": {},
   "source": [
    "# inference_mode\n",
    "启用或禁用推理模式的上下文管理器.  \n",
    "InferenceMode是在pytorch1.10版本中引入的新功能，是一个类似于 no_grad 的新上下文管理器，该模式禁用了视图跟踪和版本计数器，所以在此模式下运行代码能够获得更好的性能，速度也会更快。\n",
    "其参数表示是否启用推理模式。\n",
    "\n",
    "**定义**：  \n",
    "torch.inference_mode(mode=True)\n",
    "\n",
    "**参数**:  \n",
    "- mode (bool) – Flag whether to enable or disable inference mode  标记是否启用或禁用推理模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adf899d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Inference tensors do not track version counter.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m   y \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39m x\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m----> 6\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39;49m_version)\n\u001b[0;32m      7\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39minference_mode()\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(x):\n\u001b[0;32m      9\u001b[0m   \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Inference tensors do not track version counter."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(1, 2, 3, requires_grad=True)\n",
    "with torch.inference_mode():\n",
    "  y = x * x\n",
    "print(y.requires_grad)\n",
    "print(y._version) # inference_mode下就没有版本跟踪了\n",
    "@torch.inference_mode()\n",
    "def func(x):\n",
    "  return x * x\n",
    "out = func(x)\n",
    "out.requires_grad\n",
    "print(y._version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95785460",
   "metadata": {},
   "source": [
    "# is_inference_mode_enabled\n",
    "如果当前启用推理模式，则返回True。\n",
    "\n",
    "**定义**：  \n",
    "torch.is_inference_mode_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb4fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(1, 2, 3, requires_grad=True)\n",
    "\n",
    "print(torch.is_inference_mode_enabled())\n",
    "with torch.inference_mode():\n",
    "    y = x * x\n",
    "    print(torch.is_inference_mode_enabled())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
