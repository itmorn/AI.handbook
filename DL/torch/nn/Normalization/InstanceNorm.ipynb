{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c202a11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Normalization/InstanceNorm.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# InstanceNorm2d\n",
    "在4D输入(NCHW)上应用Layer Normalization，论文参考[Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022)\n",
    "\n",
    "**定义**：  \n",
    "torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)\n",
    "\n",
    "**公式**：  \n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "和BN类似，参数可参考BN的讲解"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c679ddde",
   "metadata": {},
   "source": [
    "# 图解train模式下的前向传播过程\n",
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://raw.githubusercontent.com/itmorn/AI.handbook/main/DL/torch/nn/Normalization/imgs/InstanceNorm.svg\">\n",
    "<img src=\"./imgs/InstanceNorm.svg\"\n",
    "    width=\"2000\" /></a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d011221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([[[[ 1.,  6.],\n",
      "          [ 9.,  4.]],\n",
      "\n",
      "         [[12., 18.],\n",
      "          [13., 11.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  7.],\n",
      "          [ 3.,  8.]],\n",
      "\n",
      "         [[19., 17.],\n",
      "          [15., 11.]]]]) \n",
      "\n",
      "output:\n",
      " tensor([[[[-1.3720,  0.3430],\n",
      "          [ 1.3720, -0.3430]],\n",
      "\n",
      "         [[-0.5571,  1.6713],\n",
      "          [-0.1857, -0.9285]]],\n",
      "\n",
      "\n",
      "        [[[-1.1767,  0.7845],\n",
      "          [-0.7845,  1.1767]],\n",
      "\n",
      "         [[ 1.1832,  0.5071],\n",
      "          [-0.1690, -1.5213]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 调包计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input1 = torch.tensor([\n",
    "    [\n",
    "        [[1, 6],\n",
    "         [9, 4]],\n",
    "        [[12, 18],\n",
    "         [13, 11]]],\n",
    "    [\n",
    "        [[2, 7],\n",
    "         [3, 8]],\n",
    "        [[19, 17],\n",
    "         [15, 11]]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "print(\"input1:\\n\", input1,\"\\n\")\n",
    "\n",
    "N, C, H, W = 2, 2, 2, 2\n",
    "\n",
    "m = nn.InstanceNorm2d(num_features=C, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
    "\n",
    "output = m(input1)\n",
    "print(\"output:\\n\", output,\"\\n\") # 结果和手工计算一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caef989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([[[[ 1.,  6.],\n",
      "          [ 9.,  4.]],\n",
      "\n",
      "         [[12., 18.],\n",
      "          [13., 11.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  7.],\n",
      "          [ 3.,  8.]],\n",
      "\n",
      "         [[19., 17.],\n",
      "          [15., 11.]]]]) \n",
      "\n",
      "Ex:\n",
      " tensor([[ 5.0000, 13.5000],\n",
      "        [ 5.0000, 15.5000]]) \n",
      "\n",
      "VarX:\n",
      " tensor([[8.5000, 7.2500],\n",
      "        [6.5000, 8.7500]]) \n",
      "\n",
      "input1-Ex:\n",
      " tensor([[[[ -4.0000,  -7.5000],\n",
      "          [  4.0000, -11.5000]],\n",
      "\n",
      "         [[  7.0000,   4.5000],\n",
      "          [  8.0000,  -4.5000]]],\n",
      "\n",
      "\n",
      "        [[[ -3.0000,  -6.5000],\n",
      "          [ -2.0000,  -7.5000]],\n",
      "\n",
      "         [[ 14.0000,   3.5000],\n",
      "          [ 10.0000,  -4.5000]]]]) \n",
      "\n",
      "sqrt(VarX+eps):\n",
      " tensor([[2.9155, 2.6926],\n",
      "        [2.5495, 2.9580]]) \n",
      "\n",
      "(input1-Ex)/sqrt(VarX+eps):\n",
      " tensor([[[[-1.3720, -2.7854],\n",
      "          [ 1.5689, -3.8877]],\n",
      "\n",
      "         [[ 2.4010,  1.6713],\n",
      "          [ 3.1379, -1.5213]]],\n",
      "\n",
      "\n",
      "        [[[-1.0290, -2.4140],\n",
      "          [-0.7845, -2.5355]],\n",
      "\n",
      "         [[ 4.8020,  1.2999],\n",
      "          [ 3.9223, -1.5213]]]]) \n",
      "\n",
      "[(input1-Ex)/sqrt(VarX+eps)] * γ + β:\n",
      " tensor([[[[-1.3720, -2.7854],\n",
      "          [ 1.5689, -3.8877]],\n",
      "\n",
      "         [[ 2.4010,  1.6713],\n",
      "          [ 3.1379, -1.5213]]],\n",
      "\n",
      "\n",
      "        [[[-1.0290, -2.4140],\n",
      "          [-0.7845, -2.5355]],\n",
      "\n",
      "         [[ 4.8020,  1.2999],\n",
      "          [ 3.9223, -1.5213]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 手工计算\n",
    "import torch\n",
    "\n",
    "# 这里涉及到组的计算，编程实现比较麻烦，展示起来不直观，这里就手工计算第1组，证明正确性即可。\n",
    "input1 = torch.tensor([\n",
    "    [\n",
    "        [[1, 6],\n",
    "         [9, 4]],\n",
    "        [[12, 18],\n",
    "         [13, 11]]],\n",
    "    [\n",
    "        [[2, 7],\n",
    "         [3, 8]],\n",
    "        [[19, 17],\n",
    "         [15, 11]]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"input1:\\n\", input1, \"\\n\")\n",
    "\n",
    "# 第1步：求均值和方差：\n",
    "VarX, EX = torch.var_mean(input1, dim=(2,3),unbiased=False)  # NCHW\n",
    "print(\"Ex:\\n\", EX, \"\\n\")\n",
    "print(\"VarX:\\n\", VarX, \"\\n\")\n",
    "\n",
    "# 第2步：减去均值：\n",
    "result2 = input1-EX\n",
    "print(\"input1-Ex:\\n\", result2, \"\\n\")\n",
    "\n",
    "# 第3步：求sqrt(VarX+eps)：\n",
    "eps = 1e-5\n",
    "result3 = torch.sqrt(VarX+eps)\n",
    "print(\"sqrt(VarX+eps):\\n\", result3, \"\\n\")\n",
    "\n",
    "# 第4步：第2步的结果/第3步的结果，完成batch内的数据规范化:\n",
    "result4 = result2/result3\n",
    "print(\"(input1-Ex)/sqrt(VarX+eps):\\n\", result4, \"\\n\")\n",
    "\n",
    "# 第5步：使用γ=1，β=0 进行再校正：\n",
    "γ = 1\n",
    "β = 0\n",
    "result5 = result4 * γ + β\n",
    "print(\"[(input1-Ex)/sqrt(VarX+eps)] * γ + β:\\n\", result5, \"\\n\") # 结果和图上一致\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
