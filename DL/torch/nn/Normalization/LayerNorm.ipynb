{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c202a11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Normalization/LayerNorm.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# LayerNorm\n",
    "在4D输入(NCHW)上应用Layer Normalization，论文参考[Layer Normalization](https://arxiv.org/abs/1607.06450)\n",
    "\n",
    "**定义**：  \n",
    "torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, device=None, dtype=None)\n",
    "\n",
    "**公式**：  \n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "和BN类似，参数可参考BN的讲解"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c679ddde",
   "metadata": {},
   "source": [
    "# 图解train模式下的前向传播过程\n",
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://raw.githubusercontent.com/itmorn/AI.handbook/main/DL/torch/nn/Normalization/imgs/LayerNorm.svg\">\n",
    "<img src=\"./imgs/LayerNorm.svg\"\n",
    "    width=\"2000\" /></a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d011221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([[[[ 1.,  6.],\n",
      "          [ 9.,  4.]],\n",
      "\n",
      "         [[12., 18.],\n",
      "          [13., 11.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  7.],\n",
      "          [ 3.,  8.]],\n",
      "\n",
      "         [[19., 17.],\n",
      "          [15., 11.]]]]) \n",
      "\n",
      "output:\n",
      " tensor([[[[-1.6199, -0.6381],\n",
      "          [-0.0491, -1.0308]],\n",
      "\n",
      "         [[ 0.5400,  1.7181],\n",
      "          [ 0.7363,  0.3436]]],\n",
      "\n",
      "\n",
      "        [[[-1.3908, -0.5479],\n",
      "          [-1.2222, -0.3793]],\n",
      "\n",
      "         [[ 1.4751,  1.1379],\n",
      "          [ 0.8008,  0.1264]]]], grad_fn=<NativeLayerNormBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 调包计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input1 = torch.tensor([\n",
    "    [\n",
    "        [[1, 6],\n",
    "         [9, 4]],\n",
    "        [[12, 18],\n",
    "         [13, 11]]],\n",
    "    [\n",
    "        [[2, 7],\n",
    "         [3, 8]],\n",
    "        [[19, 17],\n",
    "         [15, 11]]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "print(\"input1:\\n\", input1,\"\\n\")\n",
    "\n",
    "N, C, H, W = 2, 2, 2, 2\n",
    "\n",
    "m = nn.LayerNorm(normalized_shape=[C, H, W], eps=1e-05, elementwise_affine=True)\n",
    "\n",
    "output = m(input1)\n",
    "print(\"output:\\n\", output,\"\\n\") # 结果和手工计算一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caef989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([[[[ 1.,  6.],\n",
      "          [ 9.,  4.]],\n",
      "\n",
      "         [[12., 18.],\n",
      "          [13., 11.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  7.],\n",
      "          [ 3.,  8.]],\n",
      "\n",
      "         [[19., 17.],\n",
      "          [15., 11.]]]]) \n",
      "\n",
      "Ex:\n",
      " tensor([ 9.2500, 10.2500]) \n",
      "\n",
      "VarX:\n",
      " tensor([25.9375, 35.1875]) \n",
      "\n",
      "input1-Ex:\n",
      " tensor([[[[-8.2500, -4.2500],\n",
      "          [-0.2500, -6.2500]],\n",
      "\n",
      "         [[ 2.7500,  7.7500],\n",
      "          [ 3.7500,  0.7500]]],\n",
      "\n",
      "\n",
      "        [[[-7.2500, -3.2500],\n",
      "          [-6.2500, -2.2500]],\n",
      "\n",
      "         [[ 9.7500,  6.7500],\n",
      "          [ 5.7500,  0.7500]]]]) \n",
      "\n",
      "sqrt(VarX+eps):\n",
      " tensor([5.0929, 5.9319]) \n",
      "\n",
      "(input1-Ex)/sqrt(VarX+eps):\n",
      " tensor([[[[-1.6199, -0.7165],\n",
      "          [-0.0491, -1.0536]],\n",
      "\n",
      "         [[ 0.5400,  1.3065],\n",
      "          [ 0.7363,  0.1264]]],\n",
      "\n",
      "\n",
      "        [[[-1.4236, -0.5479],\n",
      "          [-1.2272, -0.3793]],\n",
      "\n",
      "         [[ 1.9144,  1.1379],\n",
      "          [ 1.1290,  0.1264]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 手工计算\n",
    "import torch\n",
    "\n",
    "# 这里涉及到组的计算，编程实现比较麻烦，展示起来不直观，这里就手工计算第1组，证明正确性即可。\n",
    "input1 = torch.tensor([\n",
    "    [\n",
    "        [[1, 6],\n",
    "         [9, 4]],\n",
    "        [[12, 18],\n",
    "         [13, 11]]],\n",
    "    [\n",
    "        [[2, 7],\n",
    "         [3, 8]],\n",
    "        [[19, 17],\n",
    "         [15, 11]]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"input1:\\n\", input1, \"\\n\")\n",
    "\n",
    "# 第1步：求均值和方差：\n",
    "VarX, EX = torch.var_mean(input1, dim=(1,2,3),unbiased=False)  # NCHW\n",
    "print(\"Ex:\\n\", EX, \"\\n\")\n",
    "print(\"VarX:\\n\", VarX, \"\\n\")\n",
    "\n",
    "# 第2步：减去均值：\n",
    "result2 = input1-EX\n",
    "print(\"input1-Ex:\\n\", result2, \"\\n\")\n",
    "\n",
    "# 第3步：求sqrt(VarX+eps)：\n",
    "eps = 1e-5\n",
    "result3 = torch.sqrt(VarX+eps)\n",
    "print(\"sqrt(VarX+eps):\\n\", result3, \"\\n\")\n",
    "\n",
    "# 第4步：第2步的结果/第3步的结果，完成batch内的数据规范化:\n",
    "result4 = result2/result3\n",
    "print(\"(input1-Ex)/sqrt(VarX+eps):\\n\", result4, \"\\n\")\n",
    "\n",
    "# 第5步：使用γ=1，β=0 进行再校正：\n",
    "γ = 1\n",
    "β = 0\n",
    "result5 = result4 * γ + β\n",
    "print(\"[(input1-Ex)/sqrt(VarX+eps)] * γ + β:\\n\", result5, \"\\n\") # 结果和图上一致\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
