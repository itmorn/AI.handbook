{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c202a11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Normalization/GroupNorm.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# GroupNorm\n",
    "对小批输入应用组归一化，参考：[Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "\n",
    "**定义**：  \n",
    "torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)\n",
    "\n",
    "**公式**：  \n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "\n",
    "**参数**:  \n",
    "和BatchNorm类似\n",
    "\n",
    "- num_groups (int) – number of groups to separate the channels into.  把通道分成多少组。\n",
    "\n",
    "- num_channels (int) – number of channels expected in input.  通道数是多少。\n",
    "- eps (float) – a value added to the denominator for numerical stability. Default: 1e-5.  为数值稳定性添加到分母的值。默认值:1e-5\n",
    "- affine (bool) – a boolean value that when set to True, this module has learnable per-channel affine parameters initialized to ones (for weights) and zeros (for biases). Default: True.  一个布尔值，当设置为True时，该模块具有可学习的仿射参数(也就是 全一向量$γ$ 和 全零向量$β$ )。默认值:True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c679ddde",
   "metadata": {},
   "source": [
    "# 图解train模式下的前向传播过程\n",
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://raw.githubusercontent.com/itmorn/AI.handbook/main/DL/torch/nn/Normalization/imgs/GroupNorm.svg\">\n",
    "<img src=\"./imgs/GroupNorm.svg\"\n",
    "    width=\"2000\" /></a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe29e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([[[[ 1.,  6.],\n",
      "          [ 9.,  4.]],\n",
      "\n",
      "         [[12., 18.],\n",
      "          [13., 11.]],\n",
      "\n",
      "         [[ 1.,  2.],\n",
      "          [ 3.,  4.]],\n",
      "\n",
      "         [[ 5.,  6.],\n",
      "          [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "        [[[ 2.,  7.],\n",
      "          [ 3.,  8.]],\n",
      "\n",
      "         [[19., 17.],\n",
      "          [15., 11.]],\n",
      "\n",
      "         [[ 1.,  3.],\n",
      "          [ 5.,  7.]],\n",
      "\n",
      "         [[ 9., 11.],\n",
      "          [13., 15.]]]]) \n",
      "\n",
      "nn.BatchNorm2d默认初始化可学习参数γ=1:\n",
      " Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True) \n",
      "\n",
      "nn.BatchNorm2d默认初始化可学习参数β=0:\n",
      " Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True) \n",
      "\n",
      "output:\n",
      " tensor([[[[-1.6199, -0.6381],\n",
      "          [-0.0491, -1.0308]],\n",
      "\n",
      "         [[ 0.5400,  1.7181],\n",
      "          [ 0.7363,  0.3436]],\n",
      "\n",
      "         [[-1.5275, -1.0911],\n",
      "          [-0.6547, -0.2182]],\n",
      "\n",
      "         [[ 0.2182,  0.6547],\n",
      "          [ 1.0911,  1.5275]]],\n",
      "\n",
      "\n",
      "        [[[-1.3908, -0.5479],\n",
      "          [-1.2222, -0.3793]],\n",
      "\n",
      "         [[ 1.4751,  1.1379],\n",
      "          [ 0.8008,  0.1264]],\n",
      "\n",
      "         [[-1.5275, -1.0911],\n",
      "          [-0.6547, -0.2182]],\n",
      "\n",
      "         [[ 0.2182,  0.6547],\n",
      "          [ 1.0911,  1.5275]]]], grad_fn=<NativeGroupNormBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 调包计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input1 = torch.tensor([\n",
    "    [\n",
    "        [[1, 6],\n",
    "         [9, 4]],\n",
    "        [[12, 18],\n",
    "         [13, 11]],\n",
    "        [[1, 2],\n",
    "         [3, 4]],\n",
    "        [[5, 6],\n",
    "         [7, 8]],\n",
    "    ],\n",
    "    [\n",
    "        [[2, 7],\n",
    "         [3, 8]],\n",
    "        [[19, 17],\n",
    "         [15, 11]],\n",
    "        [[1, 3],\n",
    "         [5, 7]],\n",
    "        [[9, 11],\n",
    "         [13, 15]],\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "print(\"input1:\\n\", input1, \"\\n\")\n",
    "\n",
    "# m = nn.BatchNorm2d(num_features=2, eps=1e-5, momentum=1, affine=True, track_running_stats=True)\n",
    "m = nn.GroupNorm(num_groups=2, num_channels=4, eps=1e-05,affine=True)\n",
    "m.train()\n",
    "\n",
    "print(\"nn.BatchNorm2d默认初始化可学习参数γ=1:\\n\", m.weight, \"\\n\")\n",
    "print(\"nn.BatchNorm2d默认初始化可学习参数β=0:\\n\", m.bias, \"\\n\")\n",
    "\n",
    "output = m(input1)\n",
    "print(\"output:\\n\", output, \"\\n\")  # 结果和手工计算一致\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c3221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_part:\n",
      " tensor([[[ 1.,  6.],\n",
      "         [ 9.,  4.]],\n",
      "\n",
      "        [[12., 18.],\n",
      "         [13., 11.]]]) \n",
      "\n",
      "Ex:\n",
      " tensor(9.2500) \n",
      "\n",
      "VarX:\n",
      " tensor(25.9375) \n",
      "\n",
      "input1-Ex:\n",
      " tensor([[[-8.2500, -3.2500],\n",
      "         [-0.2500, -5.2500]],\n",
      "\n",
      "        [[ 2.7500,  8.7500],\n",
      "         [ 3.7500,  1.7500]]]) \n",
      "\n",
      "sqrt(VarX+eps):\n",
      " tensor(5.0929) \n",
      "\n",
      "(input1-Ex)/sqrt(VarX+eps):\n",
      " tensor([[[-1.6199, -0.6381],\n",
      "         [-0.0491, -1.0308]],\n",
      "\n",
      "        [[ 0.5400,  1.7181],\n",
      "         [ 0.7363,  0.3436]]]) \n",
      "\n",
      "[(input1-Ex)/sqrt(VarX+eps)] * γ + β:\n",
      " tensor([[[-1.6199, -0.6381],\n",
      "         [-0.0491, -1.0308]],\n",
      "\n",
      "        [[ 0.5400,  1.7181],\n",
      "         [ 0.7363,  0.3436]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 手工计算\n",
    "import torch\n",
    "\n",
    "# 这里涉及到组的计算，编程实现比较麻烦，展示起来不直观，这里就手工计算第1组，证明正确性即可。\n",
    "input_part = torch.tensor([\n",
    "    [[1, 6],\n",
    "     [9, 4]],\n",
    "    [[12, 18],\n",
    "     [13, 11]]], dtype=torch.float32)\n",
    "\n",
    "print(\"input_part:\\n\", input_part, \"\\n\")\n",
    "\n",
    "# 第1步：求均值和方差：\n",
    "VarX, EX = torch.var_mean(input_part, unbiased=False)  # NCHW\n",
    "print(\"Ex:\\n\", EX, \"\\n\")\n",
    "print(\"VarX:\\n\", VarX, \"\\n\")\n",
    "\n",
    "# 第2步：减去均值：\n",
    "result2 = input_part-EX\n",
    "print(\"input1-Ex:\\n\", result2, \"\\n\")\n",
    "\n",
    "# 第3步：求sqrt(VarX+eps)：\n",
    "eps = 1e-5\n",
    "result3 = torch.sqrt(VarX+eps)\n",
    "print(\"sqrt(VarX+eps):\\n\", result3, \"\\n\")\n",
    "\n",
    "# 第4步：第2步的结果/第3步的结果，完成batch内的数据规范化:\n",
    "result4 = result2/result3\n",
    "print(\"(input1-Ex)/sqrt(VarX+eps):\\n\", result4, \"\\n\")\n",
    "\n",
    "# 第5步：使用γ=1，β=0 进行再校正：\n",
    "γ = 1\n",
    "β = 0\n",
    "result5 = result4 * γ + β\n",
    "print(\"[(input1-Ex)/sqrt(VarX+eps)] * γ + β:\\n\", result5, \"\\n\") # 结果和图上一致\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
