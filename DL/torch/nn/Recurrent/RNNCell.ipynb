{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e625b5",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Recurrent/RNNCell.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# RNNCell\n",
    "\n",
    "**定义**：   \n",
    "torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', device=None, dtype=None)\n",
    "\n",
    "**公式**：\n",
    "$$h' = \\tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})$$\n",
    "\n",
    "**参数**：  \n",
    "- input_size (int) – The number of expected features in the input x.  时间序列某一时刻的特征向量长度\n",
    "\n",
    "- hidden_size (int) – The number of features in the hidden state h.  隐藏层向量长度\n",
    "\n",
    "- bias (bool) – If False, then the layer does not use bias weights b_ih and b_hh. Default: True.  是否加待学习的偏置项\n",
    "\n",
    "- nonlinearity (str) – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'  使用什么激活函数输出"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38fd4b85",
   "metadata": {},
   "source": [
    "# 图解前向过程\n",
    "<p align=\"center\">\n",
    "<a href=\"https://raw.githubusercontent.com/itmorn/AI.handbook/main/DL/torch/nn/Recurrent/imgs/RNNCell.svg\">\n",
    "<img src=\"./imgs/RNNCell.svg\"\n",
    "    width=\"2000\" /></a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a5a4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " tensor([[[-2.1188,  0.0635, -1.4555, -0.0126, -0.1548]],\n",
      "\n",
      "        [[-0.0927,  2.5916,  0.4542, -0.6890, -0.9962]]]) \n",
      "\n",
      "weight_hh:\n",
      " Parameter containing:\n",
      "tensor([[-0.2772, -0.0332,  0.2074, -0.0931,  0.1526,  0.0440,  0.2636],\n",
      "        [-0.1062,  0.2885,  0.0995,  0.1455, -0.2869,  0.3311,  0.1348],\n",
      "        [ 0.1397, -0.2116, -0.0324,  0.0882, -0.0749, -0.1945, -0.3384],\n",
      "        [-0.0382, -0.1308, -0.2504,  0.0554, -0.1424, -0.1774,  0.0875],\n",
      "        [ 0.2736, -0.1206,  0.1587, -0.3121,  0.0490,  0.3707, -0.2204],\n",
      "        [-0.2081, -0.2066,  0.0943,  0.1093, -0.3709, -0.2986, -0.3343],\n",
      "        [ 0.2966, -0.3561, -0.2856,  0.1738,  0.0425, -0.2627,  0.2132]],\n",
      "       requires_grad=True) \n",
      "\n",
      "bias_hh:\n",
      " Parameter containing:\n",
      "tensor([-0.2760, -0.0189, -0.3539,  0.0257,  0.3023,  0.1228,  0.0330],\n",
      "       requires_grad=True) \n",
      "\n",
      "weight_ih:\n",
      " Parameter containing:\n",
      "tensor([[-0.1789, -0.0995,  0.0026,  0.3091, -0.0904],\n",
      "        [ 0.1919, -0.0633, -0.3712, -0.3278,  0.2352],\n",
      "        [-0.1763, -0.3325, -0.1452, -0.1599,  0.2960],\n",
      "        [ 0.0846, -0.0725, -0.0321, -0.0733, -0.3574],\n",
      "        [ 0.3390, -0.0081, -0.2312, -0.3536, -0.3410],\n",
      "        [ 0.0295,  0.0460,  0.0133,  0.1890, -0.0053],\n",
      "        [-0.0326, -0.1955, -0.0775, -0.1588, -0.1226]], requires_grad=True) \n",
      "\n",
      "bias_ih:\n",
      " Parameter containing:\n",
      "tensor([ 0.0746,  0.2155,  0.0508,  0.2151,  0.1789, -0.1525, -0.1883],\n",
      "       requires_grad=True) \n",
      "\n",
      "h_0:\n",
      " tensor([[ 0.6441, -0.4491, -0.4235,  0.0415,  1.0772,  0.0875, -0.3098]]) \n",
      "\n",
      "h_1:\n",
      " tensor([[ 0.0088, -0.2562,  0.4023,  0.1061,  0.4299, -0.4692,  0.4391]],\n",
      "       grad_fn=<TanhBackward0>) \n",
      "\n",
      "h_2:\n",
      " tensor([[-0.3130, -0.3809, -0.8931,  0.4103,  0.6179, -0.0974, -0.2260]],\n",
      "       grad_fn=<TanhBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "L = 2  # sequence_length  也可理解为时间步数\n",
    "N = 1  # batch_size\n",
    "H_in = 5  # input_size 输入层特征向量的长度\n",
    "H_out = 7  # hidden_size 隐藏层向量的长度\n",
    "\n",
    "input = torch.randn(L, N, H_in)\n",
    "print(\"input:\\n\", input, \"\\n\")\n",
    "\n",
    "rnn = nn.RNNCell(input_size=H_in, hidden_size=H_out, bias=True, nonlinearity='tanh')\n",
    "print(\"weight_hh:\\n\", rnn.weight_hh, \"\\n\")\n",
    "print(\"bias_hh:\\n\", rnn.bias_hh, \"\\n\")\n",
    "print(\"weight_ih:\\n\", rnn.weight_ih, \"\\n\")\n",
    "print(\"bias_ih:\\n\", rnn.bias_ih, \"\\n\")\n",
    "\n",
    "h = torch.randn(N, H_out)\n",
    "print(\"h_0:\\n\", h, \"\\n\") \n",
    "\n",
    "output = [] #保存每个时刻的隐藏层的数据\n",
    "for i in range(L):\n",
    "    h = rnn(input[i], h)\n",
    "    print(f\"h_{i+1}:\\n\", h, \"\\n\")\n",
    "    output.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a2c716e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0089],\n",
       "        [-0.2561],\n",
       "        [ 0.4023],\n",
       "        [ 0.1060],\n",
       "        [ 0.4300],\n",
       "        [-0.4691],\n",
       "        [ 0.4390]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.tensor([[0.6441, -0.4491, -0.4235, 0.0415, 1.0772, 0.0875, -0.3098]]).T\n",
    "X_1 = torch.tensor([[-2.1188,  0.0635, -1.4555, -0.0126, -0.1548]]).T\n",
    "\n",
    "weight_hh = torch.tensor([[-0.2772, -0.0332,  0.2074, -0.0931,  0.1526,  0.0440,  0.2636],\n",
    "                        [-0.1062,  0.2885,  0.0995,  0.1455, -0.2869,  0.3311,  0.1348],\n",
    "                        [ 0.1397, -0.2116, -0.0324,  0.0882, -0.0749, -0.1945, -0.3384],\n",
    "                        [-0.0382, -0.1308, -0.2504,  0.0554, -0.1424, -0.1774,  0.0875],\n",
    "                        [ 0.2736, -0.1206,  0.1587, -0.3121,  0.0490,  0.3707, -0.2204],\n",
    "                        [-0.2081, -0.2066,  0.0943,  0.1093, -0.3709, -0.2986, -0.3343],\n",
    "                        [ 0.2966, -0.3561, -0.2856,  0.1738,  0.0425, -0.2627,  0.2132]])\n",
    "bias_hh = torch.tensor([[-0.2760, -0.0189, -0.3539,  0.0257,  0.3023,  0.1228,  0.0330]]).T\n",
    "\n",
    "weight_ih = torch.tensor([[-0.1789, -0.0995,  0.0026,  0.3091, -0.0904],\n",
    "                            [ 0.1919, -0.0633, -0.3712, -0.3278,  0.2352],\n",
    "                            [-0.1763, -0.3325, -0.1452, -0.1599,  0.2960],\n",
    "                            [ 0.0846, -0.0725, -0.0321, -0.0733, -0.3574],\n",
    "                            [ 0.3390, -0.0081, -0.2312, -0.3536, -0.3410],\n",
    "                            [ 0.0295,  0.0460,  0.0133,  0.1890, -0.0053],\n",
    "                            [-0.0326, -0.1955, -0.0775, -0.1588, -0.1226]])\n",
    "bias_ih = torch.tensor([[ 0.0746,  0.2155,  0.0508,  0.2151,  0.1789, -0.1525, -0.1883]]).T\n",
    "\n",
    "# torch.tensor([[ 0.0088, -0.2562,  0.4023,  0.1061,  0.4299, -0.4692,  0.4391]]).T\n",
    "weight_hh_and_ih = torch.concat([weight_hh,weight_ih],dim=1)\n",
    "hidden_and_input = torch.concat([h_0,X_1],dim=0)\n",
    "torch.tanh(torch.mm(weight_hh_and_ih,hidden_and_input) + bias_hh + bias_ih) # 可以看到和图中的h_1一致"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "577d3767",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
