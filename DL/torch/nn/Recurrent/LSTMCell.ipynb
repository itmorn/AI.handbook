{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e625b5",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Recurrent/LSTMCell.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcf66449",
   "metadata": {},
   "source": [
    "# RNNCell  VS  LSTMCell\n",
    "\n",
    "在RNNCell中是由hx来维护“记忆”的，但是由于其变化较快，下一时刻的哪怕是不重要的输入都会大幅度改变之前的“记忆”，这就导致RNNCell不能从较长的序列中提取有效信息；  \n",
    "而在LSTMCell中，使用cx来维护“记忆”，hx主要是控制向“记忆”中加入信息和遗忘信息的，比如某时刻遇到一个不重要的输入，hx就可以控制不要去对记忆做任何操作，当输出当前步的隐状态时，还要用当前时刻的记忆去控制每个记忆位置输出的强度。因此这种结构就决定了，我们能从较长的序列中提取有效信息。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d9e8348",
   "metadata": {},
   "source": [
    "# 为什么叫LSTM\n",
    "长短期记忆网络（Long Short-Term Memory），主要强调他能够维持比较长程或短程的记忆。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# LSTMCell\n",
    "\n",
    "**定义**：   \n",
    "torch.nn.LSTMCell(input_size, hidden_size, bias=True, device=None, dtype=None)\n",
    "\n",
    "**公式**：\n",
    "$$\\begin{array}{ll}\n",
    "        i = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\n",
    "        f = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\n",
    "        g = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\n",
    "        o = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\n",
    "        c' = f * c + i * g \\\\\n",
    "        h' = o * \\tanh(c') \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "**参数**：  \n",
    "- input_size (int) – The number of expected features in the input x.  时间序列某一时刻的特征向量长度\n",
    "\n",
    "- hidden_size (int) – The number of features in the hidden state h.  隐藏层向量长度\n",
    "\n",
    "- bias (bool) – If False, then the layer does not use bias weights b_ih and b_hh. Default: True.  是否加待学习的偏置项\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38fd4b85",
   "metadata": {},
   "source": [
    "# 图解前向过程\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/LSTM2-notation.png\"\n",
    "    width=\"700\" /></p>\n",
    "    \n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/LSTM3-chain.png\"\n",
    "    width=\"1000\" /></p>\n",
    "\n",
    "    \n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/LSTMCell.svg\"\n",
    "    width=\"2000\" /></p>\n",
    "\n",
    "<!-- <p align=\"center\">\n",
    "<a href=\"https://raw.githubusercontent.com/itmorn/AI.handbook/main/DL/torch/nn/Recurrent/imgs/RNNCell.svg\">\n",
    "<img src=\"./imgs/RNNCell.svg\"\n",
    "    width=\"2000\" /></a></p> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5a4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " tensor([[[-2.1188,  0.0635, -1.4555]],\n",
      "\n",
      "        [[-0.0126, -0.1548, -0.0927]]]) \n",
      "\n",
      "h_0:\n",
      " tensor([[ 2.5916,  0.4542, -0.6890, -0.9962]]) \n",
      "\n",
      "c_0:\n",
      " tensor([[0.1856, 0.1476, 0.8628, 0.2379]]) \n",
      "\n",
      "weight_hh:\n",
      " Parameter containing:\n",
      "tensor([[-0.0506, -0.1730, -0.3312,  0.0733],\n",
      "        [-0.1884, -0.2347,  0.1158,  0.3620],\n",
      "        [-0.1595,  0.2099, -0.4129,  0.0649],\n",
      "        [ 0.4904, -0.2916, -0.2753, -0.2733],\n",
      "        [ 0.1248,  0.1446, -0.4906, -0.3950],\n",
      "        [-0.4422,  0.3924, -0.4710, -0.3778],\n",
      "        [ 0.2299,  0.0562, -0.3475,  0.2820],\n",
      "        [ 0.0986,  0.2850,  0.0672,  0.2846],\n",
      "        [ 0.2367, -0.2018, -0.2490, -0.3651],\n",
      "        [-0.0249, -0.4682,  0.0340,  0.3999],\n",
      "        [ 0.1624,  0.0436,  0.3629, -0.4253],\n",
      "        [ 0.0332, -0.3253, -0.1894, -0.3643],\n",
      "        [-0.4892, -0.3443, -0.4984, -0.0707],\n",
      "        [ 0.1803, -0.3030, -0.2147, -0.1813],\n",
      "        [-0.2879,  0.1350, -0.3416,  0.1918],\n",
      "        [ 0.3599,  0.4089,  0.2544,  0.0915]], requires_grad=True) \n",
      "\n",
      "weight_ih:\n",
      " Parameter containing:\n",
      "tensor([[-0.4336,  0.3111, -0.2333],\n",
      "        [-0.4399, -0.1921, -0.2115],\n",
      "        [ 0.3916,  0.1119, -0.0959],\n",
      "        [-0.0424, -0.0969, -0.4728],\n",
      "        [ 0.4485, -0.0107, -0.3058],\n",
      "        [-0.4678, -0.4511,  0.0390],\n",
      "        [ 0.0608,  0.0176,  0.2500],\n",
      "        [-0.0070, -0.0432, -0.2586],\n",
      "        [-0.1025, -0.2100, -0.1622],\n",
      "        [-0.3667, -0.0440,  0.2744],\n",
      "        [-0.1232,  0.2019,  0.0582],\n",
      "        [ 0.3487, -0.1404,  0.3816],\n",
      "        [ 0.1317,  0.1924, -0.3796],\n",
      "        [ 0.4379,  0.1783,  0.1848],\n",
      "        [-0.2799, -0.0428,  0.1167],\n",
      "        [-0.0991, -0.2574, -0.4477]], requires_grad=True) \n",
      "\n",
      "h_1:\n",
      " tensor([[ 0.2202, -0.0278,  0.2574, -0.3888]], grad_fn=<MulBackward0>) \n",
      "\n",
      "c_1:\n",
      " tensor([[ 0.8194, -0.0751,  0.6597, -0.4974]], grad_fn=<AddBackward0>) \n",
      "\n",
      "h_2:\n",
      " tensor([[ 0.2121, -0.0551,  0.1740, -0.1036]], grad_fn=<MulBackward0>) \n",
      "\n",
      "c_2:\n",
      " tensor([[ 0.5099, -0.1099,  0.4154, -0.1924]], grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 调包计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "L = 2  # sequence_length  也可理解为time_steps\n",
    "N = 1  # batch_size\n",
    "H_in = 3  # input_size 输入层特征向量的长度\n",
    "H_out = 4  # hidden_size 隐藏层向量的长度\n",
    "\n",
    "input = torch.randn(L, N, H_in) # (time_steps, batch, input_size)\n",
    "h = torch.randn(N, H_out) # (batch, hidden_size) 负责决定如何改变“记忆”\n",
    "c = torch.randn(N, H_out) # (batch, hidden_size) 负责维护“记忆”\n",
    "print(\"input:\\n\", input, \"\\n\")\n",
    "print(\"h_0:\\n\", h, \"\\n\")\n",
    "print(\"c_0:\\n\", c, \"\\n\")\n",
    "\n",
    "lstm_cell = nn.LSTMCell(H_in, H_out, bias=False) # (input_size, hidden_size) 为了画图简洁，不要偏置项\n",
    "print(\"weight_hh:\\n\", lstm_cell.weight_hh, \"\\n\")\n",
    "print(\"weight_ih:\\n\", lstm_cell.weight_ih, \"\\n\")\n",
    "\n",
    "output = []  #保存每个时刻的隐藏层的数据\n",
    "for i in range(input.size()[0]):\n",
    "    h, c = lstm_cell(input[i], (h, c))\n",
    "    print(f\"h_{i+1}:\\n\", h, \"\\n\")\n",
    "    print(f\"c_{i+1}:\\n\", c, \"\\n\")\n",
    "    output.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "682d0985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2235],\n",
      "        [ 0.1924],\n",
      "        [-0.7812],\n",
      "        [ 2.3723],\n",
      "        [ 0.6148],\n",
      "        [ 0.6389],\n",
      "        [ 0.0883],\n",
      "        [ 0.4436],\n",
      "        [ 1.4970],\n",
      "        [-0.3242],\n",
      "        [ 0.8035],\n",
      "        [-0.8715],\n",
      "        [-0.7247],\n",
      "        [-0.5273],\n",
      "        [-0.2200],\n",
      "        [ 1.6973]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8194],\n",
       "         [-0.0751],\n",
       "         [ 0.6596],\n",
       "         [-0.4973]]),\n",
       " tensor([[ 0.2202],\n",
       "         [-0.0278],\n",
       "         [ 0.2574],\n",
       "         [-0.3888]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手工计算\n",
    "X_1 = torch.tensor([[-2.1188,  0.0635, -1.4555]]).T\n",
    "h_0 = torch.tensor([[2.5916,  0.4542, -0.6890, -0.9962]]).T\n",
    "c_0 = torch.tensor([[0.1856, 0.1476, 0.8628, 0.2379]]).T\n",
    "weight_hh = torch.tensor([[-0.0506, -0.1730, -0.3312,  0.0733],\n",
    "                          [-0.1884, -0.2347,  0.1158,  0.3620],\n",
    "                          [-0.1595,  0.2099, -0.4129,  0.0649],\n",
    "                          [0.4904, -0.2916, -0.2753, -0.2733],\n",
    "                          [0.1248,  0.1446, -0.4906, -0.3950],\n",
    "                          [-0.4422,  0.3924, -0.4710, -0.3778],\n",
    "                          [0.2299,  0.0562, -0.3475,  0.2820],\n",
    "                          [0.0986,  0.2850,  0.0672,  0.2846],\n",
    "                          [0.2367, -0.2018, -0.2490, -0.3651],\n",
    "                          [-0.0249, -0.4682,  0.0340,  0.3999],\n",
    "                          [0.1624,  0.0436,  0.3629, -0.4253],\n",
    "                          [0.0332, -0.3253, -0.1894, -0.3643],\n",
    "                          [-0.4892, -0.3443, -0.4984, -0.0707],\n",
    "                          [0.1803, -0.3030, -0.2147, -0.1813],\n",
    "                          [-0.2879,  0.1350, -0.3416,  0.1918],\n",
    "                          [0.3599,  0.4089,  0.2544,  0.0915]])\n",
    "\n",
    "weight_ih = torch.tensor([[-0.4336,  0.3111, -0.2333],\n",
    "                          [-0.4399, -0.1921, -0.2115],\n",
    "                          [0.3916,  0.1119, -0.0959],\n",
    "                          [-0.0424, -0.0969, -0.4728],\n",
    "                          [0.4485, -0.0107, -0.3058],\n",
    "                          [-0.4678, -0.4511,  0.0390],\n",
    "                          [0.0608,  0.0176,  0.2500],\n",
    "                          [-0.0070, -0.0432, -0.2586],\n",
    "                          [-0.1025, -0.2100, -0.1622],\n",
    "                          [-0.3667, -0.0440,  0.2744],\n",
    "                          [-0.1232,  0.2019,  0.0582],\n",
    "                          [0.3487, -0.1404,  0.3816],\n",
    "                          [0.1317,  0.1924, -0.3796],\n",
    "                          [0.4379,  0.1783,  0.1848],\n",
    "                          [-0.2799, -0.0428,  0.1167],\n",
    "                          [-0.0991, -0.2574, -0.4477]])\n",
    "weight_hh_and_ih = torch.concat([weight_hh, weight_ih], dim=1)\n",
    "hidden_and_input = torch.concat([h_0, X_1], dim=0)\n",
    "result_mm = torch.mm(weight_hh_and_ih, hidden_and_input)\n",
    "print(result_mm)\n",
    "σ1 = torch.sigmoid(result_mm[4:8, :])\n",
    "σ2 = torch.sigmoid(result_mm[:4, :])\n",
    "tanh3 = torch.tanh(result_mm[8:12, :]) \n",
    "σ4 = torch.sigmoid(result_mm[12:, :])\n",
    "\n",
    "c_0*σ1\n",
    "σ2*tanh3\n",
    "c_1 = c_0*σ1+σ2*tanh3\n",
    "torch.tanh(c_0*σ1+σ2*tanh3)\n",
    "h_1 = torch.tanh(c_0*σ1+σ2*tanh3)*σ4\n",
    "\n",
    "c_1, h_1\n",
    "# c_1: tensor([[ 0.8194, -0.0751,  0.6597, -0.4974]], grad_fn=<AddBackward0>) \n",
    "# h_1: tensor([[ 0.2202, -0.0278,  0.2574, -0.3888]], grad_fn=<MulBackward0>) \n",
    "# 可以看到和调包计算结果一致"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06d2be26",
   "metadata": {},
   "source": [
    "# netron可视化计算图\n",
    "我们也可以输出LSTMCell的计算图，然后通过 https://netron.app/ 查看\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/LSTMCell_netron.svg\"\n",
    "    width=\"800\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3886668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出完成\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "L = 2  # sequence_length  也可理解为time_steps\n",
    "N = 1  # batch_size\n",
    "H_in = 3  # input_size 输入层特征向量的长度\n",
    "H_out = 4  # hidden_size 隐藏层向量的长度\n",
    "\n",
    "input = torch.randn(L, N, H_in) # (time_steps, batch, input_size)\n",
    "h = torch.randn(N, H_out) # (batch, hidden_size) 负责决定如何改变“记忆”\n",
    "c = torch.randn(N, H_out) # (batch, hidden_size) 负责维护“记忆”\n",
    "\n",
    "lstm_cell = nn.LSTMCell(H_in, H_out, bias=False) # (input_size, hidden_size) 为了画图简洁，不要偏置项\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import onnx.utils\n",
    "import onnx.version_converter\n",
    "\n",
    "torch.onnx.export(\n",
    "    lstm_cell,\n",
    "    input[0],\n",
    "    'LSTMCell.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    ")\n",
    "\n",
    "# 增加维度信息\n",
    "model_file = 'LSTMCell.onnx'\n",
    "onnx_model = onnx.load(model_file)\n",
    "onnx.save(onnx.shape_inference.infer_shapes(onnx_model), model_file)\n",
    "print(\"输出完成\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "577d3767",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
