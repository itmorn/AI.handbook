{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e625b5",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Recurrent/RNN.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cbe6a0e",
   "metadata": {},
   "source": [
    "# RNN和RNNCell的区别 \n",
    "RNN和RNNCell层的区别在于前者一次能够处理整个序列，而后者一次只处理序列中一个时间点的数据，前者封装更完备更易于使用，后者更具灵活性。 实际上RNN层的一种后端实现方式就是调用RNNCell来实现的。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998d1914",
   "metadata": {},
   "source": [
    "# RNN\n",
    "**定义**：   \n",
    "torch.nn.RNN(*args, **kwargs)\n",
    "**公式**：\n",
    "$$h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$\n",
    "\n",
    "**参数**：  \n",
    "- input_size (int) – The number of expected features in the input x.  时间序列某一时刻的特征向量长度\n",
    "\n",
    "- hidden_size (int) – The number of features in the hidden state h.  隐藏层向量长度\n",
    "\n",
    "- num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1    循环层数。例如，设置num_layers=2意味着将两个RNN堆叠在一起形成一个堆叠的RNN，第二个RNN接收第一个RNN的输出并计算最终结果。默认值:1\n",
    "\n",
    "- nonlinearity (str) – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'  使用什么激活函数输出\n",
    "\n",
    "- bias (bool) – If False, then the layer does not use bias weights b_ih and b_hh. Default: True.  是否加待学习的偏置项\n",
    "\n",
    "- batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False  是否要把N放在L之前\n",
    "\n",
    "- dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "\n",
    "- bidirectional – If True, becomes a bidirectional RNN. Default: False  是否为双向RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f9d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " tensor([[[-2.1188,  0.0635, -1.4555, -0.0126, -0.1548]],\n",
      "\n",
      "        [[-0.0927,  2.5916,  0.4542, -0.6890, -0.9962]]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0088, -0.2562,  0.4023,  0.1061,  0.4299, -0.4692,  0.4391]],\n",
       "\n",
       "        [[-0.3130, -0.3809, -0.8931,  0.4103,  0.6179, -0.0974, -0.2260]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "L = 2  # sequence length\n",
    "N = 1  # batch size\n",
    "H_in = 5  # input_size\n",
    "H_out = 7  # hidden_size\n",
    "num_layers = 1 \n",
    "\n",
    "input = torch.randn(L, N, H_in)\n",
    "print(\"input:\\n\", input, \"\\n\")\n",
    "\n",
    "rnn = nn.RNN(input_size=H_in, hidden_size=H_out, num_layers=num_layers, nonlinearity=\"tanh\",\n",
    "             bias=True, batch_first=False, dropout=0, bidirectional=False)\n",
    "\n",
    "\n",
    "h0 = torch.randn(num_layers, N, H_out)\n",
    "output, hn = rnn(input, h0)\n",
    "output # 可以看到，结果和RNNCell里的例子是一样的，具体内容可以查看RNNCell部分，这里不加赘述。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78102bae",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
