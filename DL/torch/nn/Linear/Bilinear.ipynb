{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e625b5",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/torch/nn/Recurrent/Bilinear.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998d1914",
   "metadata": {},
   "source": [
    "# Bilinear\n",
    "\n",
    "**定义**：   \n",
    "torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True, device=None, dtype=None)\n",
    "\n",
    "**公式**：   \n",
    "对输入数据应用线性变换:\n",
    "$$y = x_1^T A x_2 + b$$\n",
    "\n",
    "\n",
    "**参数**：  \n",
    "- in1_features (int) – size of each first input sample  第1个输入样本的尺寸\n",
    "\n",
    "- in2_features (int) – size of each second input sample  第2个输入样本的尺寸\n",
    "\n",
    "- out_features (int) – size of each output sample  每个输出样本的大小\n",
    "\n",
    "- bias (bool) – If set to False, the layer will not learn an additive bias. Default: True  如果设置为False，该层将不会学习偏置项。默认值:True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a421b60",
   "metadata": {},
   "source": [
    "# 图解\n",
    "假设input1有5个特征，input2有4个特征，Bilinear就是让其两两线性组合，然后相加求和，得到一个值，这就需要有5 * 4个权重。如果指定了out_features，则需要的权重个数为out_features * 5 * 4。\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/Bilinear.svg\"\n",
    "    width=\"700\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d397699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1:\n",
      " tensor([-2.1188,  0.0635, -1.4555, -0.0126, -0.1548]) \n",
      "\n",
      "input2:\n",
      " tensor([-0.0927,  2.5916,  0.4542, -0.6890]) \n",
      "\n",
      "weight:\n",
      " Parameter containing:\n",
      "tensor([[[-0.2116, -0.1177,  0.0031,  0.3657],\n",
      "         [-0.1070,  0.2271, -0.0749, -0.4392],\n",
      "         [-0.3878,  0.2782, -0.2086, -0.3934],\n",
      "         [-0.1719, -0.1892,  0.3502,  0.1000],\n",
      "         [-0.0857, -0.0380, -0.0867, -0.4229]],\n",
      "\n",
      "        [[ 0.4011, -0.0096, -0.2735, -0.4184],\n",
      "         [-0.4034,  0.0349,  0.0544,  0.0158],\n",
      "         [ 0.2236, -0.0063, -0.0386, -0.2313],\n",
      "         [-0.0917, -0.1879, -0.1451, -0.3280],\n",
      "         [-0.0393,  0.2454, -0.1102,  0.1806]],\n",
      "\n",
      "        [[ 0.0521,  0.3119, -0.1256,  0.3413],\n",
      "         [ 0.1178,  0.1721, -0.3395,  0.3917],\n",
      "         [ 0.1595,  0.1653, -0.2504, -0.0383],\n",
      "         [ 0.1044, -0.0887, -0.2302, -0.4004],\n",
      "         [-0.0453, -0.1547, -0.2963,  0.0656]]], requires_grad=True) \n",
      "\n",
      "bias:\n",
      " Parameter containing:\n",
      "tensor([-0.1685, -0.2100,  0.1036], requires_grad=True) \n",
      "\n",
      "output:\n",
      " tensor([-0.3567, -0.6379, -1.3637], grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 调包计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "in1_features = 5\n",
    "in2_features = 4\n",
    "out_features = 3\n",
    "\n",
    "input1 = torch.randn(in1_features)\n",
    "input2 = torch.randn(in2_features)\n",
    "print(\"input1:\\n\", input1, \"\\n\")\n",
    "print(\"input2:\\n\", input2, \"\\n\")\n",
    "\n",
    "m = nn.Bilinear(in1_features=in1_features, in2_features=in2_features,\n",
    "                out_features=out_features, bias=True)\n",
    "\n",
    "print(\"weight:\\n\", m.weight, \"\\n\")\n",
    "print(\"bias:\\n\", m.bias, \"\\n\")\n",
    "\n",
    "\n",
    "output = m(input1, input2)\n",
    "print(\"output:\\n\", output, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cec7c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([5, 4])\n",
      "tensor([[ 1.0214, -0.1329,  0.3013, -0.1659]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3563]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手工计算\n",
    "import torch\n",
    "input1 = torch.tensor([[-2.1188,  0.0635, -1.4555, -0.0126, -0.1548]])\n",
    "print(input1.shape)\n",
    "input2 = torch.tensor([[-0.0927,  2.5916,  0.4542, -0.6890]]).T\n",
    "weight = torch.tensor([[[-0.2116, -0.1177,  0.0031,  0.3657],\n",
    "                        [-0.1070,  0.2271, -0.0749, -0.4392],\n",
    "                        [-0.3878,  0.2782, -0.2086, -0.3934],\n",
    "                        [-0.1719, -0.1892,  0.3502,  0.1000],\n",
    "                        [-0.0857, -0.0380, -0.0867, -0.4229]],\n",
    "\n",
    "                       [[0.4011, -0.0096, -0.2735, -0.4184],\n",
    "                        [-0.4034,  0.0349,  0.0544,  0.0158],\n",
    "                        [0.2236, -0.0063, -0.0386, -0.2313],\n",
    "                        [-0.0917, -0.1879, -0.1451, -0.3280],\n",
    "                        [-0.0393,  0.2454, -0.1102,  0.1806]],\n",
    "\n",
    "                       [[0.0521,  0.3119, -0.1256,  0.3413],\n",
    "                        [0.1178,  0.1721, -0.3395,  0.3917],\n",
    "                        [0.1595,  0.1653, -0.2504, -0.0383],\n",
    "                        [0.1044, -0.0887, -0.2302, -0.4004],\n",
    "                        [-0.0453, -0.1547, -0.2963,  0.0656]]])\n",
    "bias = torch.tensor([-0.1685, -0.2100,  0.1036])\n",
    "print(weight[0].shape)\n",
    "print(torch.mm(input1, weight[0]))\n",
    "torch.mm(torch.mm(input1, weight[0]),input2)+bias[0]\n",
    "\n",
    "# torch.mm(torch.mm(input1, weight),input2)+bias  # 可以看到 结果是一致的\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78102bae",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
