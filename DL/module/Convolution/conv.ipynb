{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e625b5",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/itmorn/AI.handbook/blob/main/DL/module/Convolution/conv.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8662b",
   "metadata": {},
   "source": [
    "# Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34edbc",
   "metadata": {},
   "source": [
    "对由多个输入平面组成的输入信号应用1D卷积。\n",
    "\n",
    "定义：  \n",
    "torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "参数：  \n",
    "in_channels (int): Number of channels in the input image\n",
    "输入图像中的通道数\n",
    "\n",
    "out_channels (int): Number of channels produced by the convolution\n",
    "卷积产生的通道数\n",
    "\n",
    "kernel_size (int or tuple): Size of the convolving kernel\n",
    "卷积核的大小\n",
    "\n",
    "stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "卷积步幅。默认值:1\n",
    "\n",
    "padding (int, tuple or str, optional): Padding added to both sides of the input. Default: 0\n",
    "输入框两边的添加的Padding尺寸。默认值:0\n",
    "\n",
    "padding_mode (str, optional): ``'zeros'``, ``'reflect'``, ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
    "添加Padding的方式\n",
    "\n",
    "dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "卷积核元素之间的间距\n",
    "\n",
    "groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
    "分组卷积\n",
    "\n",
    "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "添加一个可学习的偏置项\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006d014",
   "metadata": {},
   "source": [
    "## 图解in_channels、out_channels、kernel_size\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/conv1d.svg\"\n",
    "    width=\"2000\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05f9d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[-0.7747,  0.7926, -0.0062, -0.4377,  0.7148],\n",
      "         [ 0.3590, -0.1242,  2.0345, -0.3479, -0.4007]],\n",
      "\n",
      "        [[ 0.8059, -0.1021,  0.3168, -0.8889,  1.1768],\n",
      "         [ 0.8074,  0.9144,  1.6259, -0.6535, -0.0865]]])\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[-0.0783, -0.0347, -0.0791],\n",
      "         [-0.3860,  0.3662, -0.0087]],\n",
      "\n",
      "        [[-0.2497, -0.3820, -0.3683],\n",
      "         [ 0.0319,  0.0496,  0.0144]]], requires_grad=True)\n",
      "output: tensor([[[-0.1682,  0.7688, -0.9502],\n",
      "         [-0.0725,  0.0577, -0.0527]],\n",
      "\n",
      "        [[-0.0756,  0.3155, -0.9533],\n",
      "         [-0.1843,  0.3324, -0.1548]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 2\n",
    "sequence_length = 5\n",
    "input = torch.randn(batch_size, in_channels, sequence_length)\n",
    "print(\"input:\",input)\n",
    "\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=1, padding=0,\n",
    "              dilation=1, groups=1, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4680baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16810998000000002\n",
      "-0.07245857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_part = np.array([\n",
    "    [-0.7747, 0.7926, -0.0062],\n",
    "    [0.3590, -0.1242, 2.0345]\n",
    "])\n",
    "\n",
    "kernel_1 = np.array([\n",
    "    [-0.0783, -0.0347, -0.0791],\n",
    "    [-0.3860, 0.3662, -0.0087]\n",
    "])\n",
    "print(np.sum(input_part*kernel_1))\n",
    "\n",
    "kernel_2 = np.array([\n",
    "    [-0.2497, -0.3820, -0.3683],\n",
    "    [0.0319,  0.0496,  0.0144]\n",
    "])\n",
    "print(np.sum(input_part*kernel_2))\n",
    "# 结果和图上会有些许差异，主要是四舍五入所导致的误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75607d01",
   "metadata": {},
   "source": [
    "## 图解stride\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/stride1d.svg\"\n",
    "    width=\"600\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f3989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[-0.7747,  0.7926, -0.0062, -0.4377,  0.7148],\n",
      "         [ 0.3590, -0.1242,  2.0345, -0.3479, -0.4007]],\n",
      "\n",
      "        [[ 0.8059, -0.1021,  0.3168, -0.8889,  1.1768],\n",
      "         [ 0.8074,  0.9144,  1.6259, -0.6535, -0.0865]]])\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[-0.0783, -0.0347, -0.0791],\n",
      "         [-0.3860,  0.3662, -0.0087]],\n",
      "\n",
      "        [[-0.2497, -0.3820, -0.3683],\n",
      "         [ 0.0319,  0.0496,  0.0144]]], requires_grad=True)\n",
      "output: tensor([[[-0.1682, -0.9502],\n",
      "         [-0.0725, -0.0527]],\n",
      "\n",
      "        [[-0.0756, -0.9533],\n",
      "         [-0.1843, -0.1548]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 2\n",
    "sequence_length = 5\n",
    "input = torch.randn(batch_size, in_channels, sequence_length)\n",
    "print(\"input:\",input)\n",
    "\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=2, padding=0,\n",
    "              dilation=1, groups=1, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output) #可以看到output减少了一列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb726e73",
   "metadata": {},
   "source": [
    "## 图解padding\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/padding1d.svg\"\n",
    "    width=\"600\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e4d84dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[-0.7747,  0.7926, -0.0062, -0.4377,  0.7148],\n",
      "         [ 0.3590, -0.1242,  2.0345, -0.3479, -0.4007]],\n",
      "\n",
      "        [[ 0.8059, -0.1021,  0.3168, -0.8889,  1.1768],\n",
      "         [ 0.8074,  0.9144,  1.6259, -0.6535, -0.0865]]])\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[-0.0783, -0.0347, -0.0791],\n",
      "         [-0.3860,  0.3662, -0.0087]],\n",
      "\n",
      "        [[-0.2497, -0.3820, -0.3683],\n",
      "         [ 0.0319,  0.0496,  0.0144]]], requires_grad=True)\n",
      "output: tensor([[[ 0.0000,  0.0582,  0.0967, -0.1682,  0.7688, -0.9502, -0.0030,\n",
      "           0.0987,  0.0000],\n",
      "         [ 0.0000,  0.2905,  0.0201, -0.0725,  0.0577, -0.0527, -0.1947,\n",
      "          -0.1912,  0.0000]],\n",
      "\n",
      "        [[ 0.0000, -0.0708,  0.2678, -0.0756,  0.3155, -0.9533,  0.2494,\n",
      "          -0.0587,  0.0000],\n",
      "         [ 0.0000, -0.2852, -0.2170, -0.1843,  0.3324, -0.1548, -0.2527,\n",
      "          -0.2966,  0.0000]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 2\n",
    "sequence_length = 5\n",
    "input = torch.randn(batch_size, in_channels, sequence_length)\n",
    "print(\"input:\",input)\n",
    "\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=1, padding=3,\n",
    "              dilation=1, groups=1, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output) #随着padding的增加，输出的长度越来越长\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444f30",
   "metadata": {},
   "source": [
    "## 图解dilation\n",
    "<img src=\"./imgs/dilation1d.svg\"\n",
    "    width=\"2000\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6303de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[-0.7747,  0.7926, -0.0062, -0.4377,  0.7148],\n",
      "         [ 0.3590, -0.1242,  2.0345, -0.3479, -0.4007]],\n",
      "\n",
      "        [[ 0.8059, -0.1021,  0.3168, -0.8889,  1.1768],\n",
      "         [ 0.8074,  0.9144,  1.6259, -0.6535, -0.0865]]])\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[-0.0783, -0.0347, -0.0791],\n",
      "         [-0.3860,  0.3662, -0.0087]],\n",
      "\n",
      "        [[-0.2497, -0.3820, -0.3683],\n",
      "         [ 0.0319,  0.0496,  0.0144]]], requires_grad=True)\n",
      "output: tensor([[[ 0.6142],\n",
      "         [ 0.0392]],\n",
      "\n",
      "        [[ 0.1173],\n",
      "         [-0.6504]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 2\n",
    "sequence_length = 5\n",
    "input = torch.randn(batch_size, in_channels, sequence_length)\n",
    "print(\"input:\",input)\n",
    "\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=1, padding=0,\n",
    "              dilation=2, groups=1, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e995900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61427946\n",
      "0.03914337000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_part = np.array([\n",
    "    [-0.7747, -0.0062, 0.7148],\n",
    "    [0.3590, 2.0345, -0.4007]\n",
    "])\n",
    "\n",
    "kernel_1 = np.array([\n",
    "    [-0.0783, -0.0347, -0.0791],\n",
    "    [-0.3860, 0.3662, -0.0087]\n",
    "])\n",
    "print(np.sum(input_part*kernel_1))\n",
    "\n",
    "kernel_2 = np.array([\n",
    "    [-0.2497, -0.3820, -0.3683],\n",
    "    [0.0319,  0.0496,  0.0144]\n",
    "])\n",
    "print(np.sum(input_part*kernel_2))\n",
    "# 结果和图上会有些许差异，主要是四舍五入所导致的误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc4ea9",
   "metadata": {},
   "source": [
    "## 图解groups\n",
    "<img src=\"./imgs/groups1d.svg\"\n",
    "    width=\"2000\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82679805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------groups=1----------------------:\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[-0.0783, -0.0347, -0.0791],\n",
      "         [-0.3860,  0.3662, -0.0087]],\n",
      "\n",
      "        [[-0.2497, -0.3820, -0.3683],\n",
      "         [ 0.0319,  0.0496,  0.0144]]], requires_grad=True)\n",
      "output: tensor([[[-0.1682,  0.7688, -0.9502],\n",
      "         [-0.0725,  0.0577, -0.0527]],\n",
      "\n",
      "        [[-0.0756,  0.3155, -0.9533],\n",
      "         [-0.1843,  0.3324, -0.1548]]], grad_fn=<ConvolutionBackward0>)\n",
      "output.shape: torch.Size([2, 2, 3])\n",
      "\n",
      "----------------------groups=2----------------------:\n",
      "m.weight: Parameter containing:\n",
      "tensor([[[ 0.2886, -0.0081, -0.0499]],\n",
      "\n",
      "        [[-0.2986, -0.1184, -0.2425]]], requires_grad=True)\n",
      "output: tensor([[[-0.2297,  0.2507, -0.0339],\n",
      "         [-0.5859, -0.1194, -0.4690]],\n",
      "\n",
      "        [[ 0.2177,  0.0123,  0.0400],\n",
      "         [-0.7437, -0.3071, -0.3871]]], grad_fn=<ConvolutionBackward0>)\n",
      "output.shape: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(666)\n",
    "\n",
    "batch_size = 2\n",
    "in_channels = 2\n",
    "sequence_length = 5\n",
    "input = torch.randn(batch_size, in_channels, sequence_length)\n",
    "# print(\"input:\",input)\n",
    "\n",
    "print(\"\\n----------------------groups=1----------------------:\")\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=1, padding=0,\n",
    "              dilation=1, groups=1, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output)\n",
    "print(\"output.shape:\",output.shape)\n",
    "\n",
    "print(\"\\n----------------------groups=2----------------------:\")\n",
    "m = nn.Conv1d(in_channels=in_channels, out_channels=2, kernel_size=3, stride=1, padding=0,\n",
    "              dilation=1, groups=2, bias=False, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "print(\"m.weight:\",m.weight)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output:\",output)\n",
    "print(\"output.shape:\",output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a739f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22968910000000003\n",
      "-0.58585837\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_part = np.array([\n",
    "    [-0.7747, 0.7926, -0.0062],\n",
    "    # [0.3590, -0.1242, 2.0345]\n",
    "])\n",
    "\n",
    "kernel_1 = np.array([\n",
    "    [0.2886, -0.0081, -0.0499]\n",
    "])\n",
    "print(np.sum(input_part*kernel_1))\n",
    "\n",
    "input_part = np.array([\n",
    "    # [-0.7747, 0.7926, -0.0062],\n",
    "    [0.3590, -0.1242, 2.0345]\n",
    "])\n",
    "\n",
    "kernel_2 = np.array([\n",
    "    [-0.2986, -0.1184, -0.2425]\n",
    "])\n",
    "print(np.sum(input_part*kernel_2))\n",
    "# 结果和图上会有些许差异，主要是四舍五入所导致的误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78102bae",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "[《人工智能导论：模型与算法》](https://item.jd.com/12653461.html)\n",
    "\n",
    "[《统计学习方法》](https://item.jd.com/12522197.html)\n",
    "\n",
    "[《机器学习》](https://item.jd.com/12762673.html)\n",
    "\n",
    "[FIVE KEY ASSUMPTIONS OF LINEAR REGRESSION ALGORITHM](https://dataaspirant.com/assumptions-of-linear-regression-algorithm/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e00c79739f2fdf113306667eb0b8e68d4274855301e6df90bc305a954991b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
